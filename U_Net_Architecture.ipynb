{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM8S6rsyy/4QeVLlgqqWfgo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install patchify"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_o78_fFnGXQ",
        "outputId": "b3933dd9-85f9-4ccd-818a-2eefacf532ff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting patchify\n",
            "  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from patchify) (1.25.2)\n",
            "Installing collected packages: patchify\n",
            "Successfully installed patchify-0.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "U-Net\n",
        "\n",
        "Segmentation of mitochondria using only 12 images and about 150 labeled objects\n",
        "\n",
        "Dataset: https://www.epfl.ch/labs/cvlab/data/data-em/\n",
        "\"\"\"\n",
        "\n",
        "from unet_model_with_functions_of_blocks import build_unet\n",
        "from keras.utils import normalize\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from patchify import patchify, unpatchify\n",
        "import tifffile as tiff\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "\n",
        "#12 images only\n",
        "large_image_stack = tiff.imread('training.tif')\n",
        "large_mask_stack = tiff.imread('testing.tif')\n",
        "\n",
        "all_img_patches = []\n",
        "for img in range(large_image_stack.shape[0]):\n",
        "    #print(img)     #just stop here to see all file names printed\n",
        "\n",
        "    large_image = large_image_stack[img]\n",
        "\n",
        "    patches_img = patchify(large_image, (256, 256), step=256)  #Step=256 for 256 patches means no overlap\n",
        "\n",
        "\n",
        "    for i in range(patches_img.shape[0]):\n",
        "        for j in range(patches_img.shape[1]):\n",
        "\n",
        "            single_patch_img = patches_img[i,j,:,:]\n",
        "            single_patch_img = (single_patch_img.astype('float32')) / 255.\n",
        "            #scaler = MinMaxScaler()\n",
        "            #single_patch_img= scaler.fit_transform(single_patch_img)\n",
        "\n",
        "            all_img_patches.append(single_patch_img)\n",
        "\n",
        "#This will split the image into small images of shape [3,3]\n",
        "images = np.array(all_img_patches)\n",
        "images = np.expand_dims(images, -1)\n",
        "\n",
        "all_mask_patches = []\n",
        "for img in range(large_mask_stack.shape[0]):\n",
        "    #print(img)     #just stop here to see all file names printed\n",
        "\n",
        "    large_mask = large_mask_stack[img]\n",
        "\n",
        "    patches_mask = patchify(large_mask, (256, 256), step=256)  #Step=256 for 256 patches means no overlap\n",
        "\n",
        "\n",
        "    for i in range(patches_mask.shape[0]):\n",
        "        for j in range(patches_mask.shape[1]):\n",
        "\n",
        "            single_patch_mask = patches_mask[i,j,:,:]\n",
        "            single_patch_mask = single_patch_mask / 255.\n",
        "\n",
        "            all_mask_patches.append(single_patch_mask)\n",
        "\n",
        "#This will split the image into small images of shape [3,3]\n",
        "masks = np.array(all_mask_patches)\n",
        "masks = np.expand_dims(masks, -1)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size = 0.25, random_state = 0)\n",
        "\n",
        "\n",
        "#Sanity check, view few mages\n",
        "import random\n",
        "import numpy as np\n",
        "image_number = random.randint(0, len(X_train))\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(121)\n",
        "plt.imshow(np.reshape(X_train[image_number], (256, 256)), cmap='gray')\n",
        "plt.subplot(122)\n",
        "plt.imshow(np.reshape(y_train[image_number], (256, 256)), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "IMG_HEIGHT = images.shape[1]\n",
        "IMG_WIDTH  = images.shape[2]\n",
        "IMG_CHANNELS = images.shape[3]\n",
        "\n",
        "\n",
        "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        "\n",
        "input_shape=tf.convert_to_tensor(input_shape)\n",
        "print(input_shape)\n",
        "print(type(input_shape))\n",
        "model = build_unet(input_shape)\n",
        "model.compile(optimizer=Adam(lr = 1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "#New generator with rotation and shear where interpolation that comes with rotation and shear are thresholded in masks.\n",
        "#This gives a binary mask rather than a mask with interpolated values.\n",
        "seed=24\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "img_data_gen_args = dict(rotation_range=90,\n",
        "                     width_shift_range=0.3,\n",
        "                     height_shift_range=0.3,\n",
        "                     shear_range=0.5,\n",
        "                     zoom_range=0.3,\n",
        "                     horizontal_flip=True,\n",
        "                     vertical_flip=True,\n",
        "                     fill_mode='reflect')\n",
        "\n",
        "mask_data_gen_args = dict(rotation_range=90,\n",
        "                     width_shift_range=0.3,\n",
        "                     height_shift_range=0.3,\n",
        "                     shear_range=0.5,\n",
        "                     zoom_range=0.3,\n",
        "                     horizontal_flip=True,\n",
        "                     vertical_flip=True,\n",
        "                     fill_mode='reflect',\n",
        "                     preprocessing_function = lambda x: np.where(x>0, 1, 0).astype(x.dtype)) #Binarize the output again.\n",
        "\n",
        "image_data_generator = ImageDataGenerator(**img_data_gen_args)\n",
        "#image_data_generator.fit(X_train, augment=True, seed=seed)\n",
        "\n",
        "batch_size= 8\n",
        "\n",
        "image_generator = image_data_generator.flow(X_train, seed=seed, batch_size=batch_size)\n",
        "valid_img_generator = image_data_generator.flow(X_test, seed=seed, batch_size=batch_size) #Default batch size 32, if not specified here\n",
        "\n",
        "mask_data_generator = ImageDataGenerator(**mask_data_gen_args)\n",
        "#mask_data_generator.fit(y_train, augment=True, seed=seed)\n",
        "mask_generator = mask_data_generator.flow(y_train, seed=seed, batch_size=batch_size)\n",
        "valid_mask_generator = mask_data_generator.flow(y_test, seed=seed, batch_size=batch_size)  #Default batch size 32, if not specified here\n",
        "\n",
        "def my_image_mask_generator(image_generator, mask_generator):\n",
        "    train_generator = zip(image_generator, mask_generator)\n",
        "    for (img, mask) in train_generator:\n",
        "        yield (img, mask)\n",
        "\n",
        "my_generator = my_image_mask_generator(image_generator, mask_generator)\n",
        "\n",
        "validation_datagen = my_image_mask_generator(valid_img_generator, valid_mask_generator)\n",
        "\n",
        "\n",
        "x = image_generator.next()\n",
        "y = mask_generator.next()\n",
        "for i in range(0,1):\n",
        "    image = x[i]\n",
        "    mask = y[i]\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(image[:,:,0], cmap='gray')\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(mask[:,:,0])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "steps_per_epoch = 3*(len(X_train))//batch_size\n",
        "\n",
        "\n",
        "history = model.fit_generator(my_generator, validation_data=validation_datagen,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    validation_steps=steps_per_epoch, epochs=25)\n",
        "\n",
        "\n",
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "#acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "#val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#IOU\n",
        "y_pred=model.predict(X_test)\n",
        "y_pred_thresholded = y_pred > 0.5\n",
        "\n",
        "intersection = np.logical_and(y_test, y_pred_thresholded)\n",
        "union = np.logical_or(y_test, y_pred_thresholded)\n",
        "iou_score = np.sum(intersection) / np.sum(union)\n",
        "print(\"IoU socre is: \", iou_score)\n",
        "\n",
        "#Predict on a few images\n",
        "#model = get_model()\n",
        "#model.load_weights('mitochondria_50_plus_100_epochs.hdf5') #Trained for 50 epochs and then additional 100\n",
        "#\n",
        "model.load_weights('mitochondria_gpu_tf1.4.hdf5')  #Trained for 50 epochs\n",
        "\n",
        "test_img_number = random.randint(0, len(X_test))\n",
        "test_img = X_test[test_img_number]\n",
        "ground_truth=y_test[test_img_number]\n",
        "test_img_norm=test_img[:,:,0][:,:,None]\n",
        "test_img_input=np.expand_dims(test_img_norm, 0)\n",
        "prediction = (model.predict(test_img_input)[0,:,:,0] > 0.2).astype(np.uint8)\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(231)\n",
        "plt.title('Testing Image')\n",
        "plt.imshow(test_img[:,:,0], cmap='gray')\n",
        "plt.subplot(232)\n",
        "plt.title('Testing Label')\n",
        "plt.imshow(ground_truth[:,:,0], cmap='gray')\n",
        "plt.subplot(233)\n",
        "plt.title('Prediction on test image')\n",
        "plt.imshow(prediction, cmap='gray')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N2MPQhYTnMdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WCDxZSMQL10L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}